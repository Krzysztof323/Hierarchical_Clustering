{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c90f8fc0",
   "metadata": {},
   "source": [
    "### Kod naszego algorytmu Hierarchical Clustering, który buduje pewną hierarchizacje klastów. Każdy punkt danych jest we własnym klastrze. Potem ten klaster szuka najbliższego klastra i łączy w jeden nowy klaster. Wedy przesuwamy się w góre w hierarchizacji aż do momentu jak połączą się w jeden klaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34040150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "    \n",
    "class HierarchicalClustering:\n",
    "    def __init__(self, n_clusters):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.clusters = []\n",
    "        self.labels = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Dane jako klastry\n",
    "        self.clusters = [[i] for i in range(len(X))]\n",
    "\n",
    "        # Pętla, która będzie się robiła do momentu wystarczającej liczby klastrów\n",
    "        while len(self.clusters) > self.n_clusters:\n",
    "            # Szukanie najbliższych klastrów\n",
    "            min_dist = math.inf\n",
    "            min_pair = None\n",
    "            for i in range(len(self.clusters)):\n",
    "                for j in range(i+1, len(self.clusters)):\n",
    "                    dist = self._distance(X, self.clusters[i], self.clusters[j])\n",
    "                    if dist < min_dist:\n",
    "                        min_dist = dist\n",
    "                        min_pair = (i, j)\n",
    "\n",
    "            # Łączenie najbliższych klastrów\n",
    "            c1, c2 = min_pair\n",
    "            self.clusters[c1] = self.clusters[c1] + self.clusters[c2]\n",
    "            self.clusters.pop(c2)\n",
    "\n",
    "        # Przydzielanie indeksów do przykładów\n",
    "        self.labels = np.zeros(len(X))\n",
    "        for i, cluster in enumerate(self.clusters):\n",
    "            for j in cluster:\n",
    "                  self.labels[j] = i\n",
    "\n",
    "    def _distance(self, X, c1, c2):\n",
    "        # Obliczenie średniej odległości pomiędzy punktami w klastrach\n",
    "        sum_dist = 0\n",
    "        for i in c1:\n",
    "            for j in c2:\n",
    "                sum_dist += np.linalg.norm(X[i] - X[j])\n",
    "        return sum_dist / (len(c1) * len(c2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0415f23f",
   "metadata": {},
   "source": [
    "### Losujemy dane od 0 do 1 z 40 wierszami i 3 kolumny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68eb9ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Wygenerowane dane\n",
    "X = np.random.rand(40, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d022f8c",
   "metadata": {},
   "source": [
    "### Implementacja naszego kodu i algorytmu z Sickit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b75c8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.30012944 0.57037159 0.6948424 ]\n",
      " [0.41468487 0.70623346 0.31380339]\n",
      " [0.5180493  0.09584303 0.85350267]\n",
      " [0.54166236 0.70694636 0.41773935]\n",
      " [0.53943068 0.05447993 0.79918779]\n",
      " [0.21163633 0.58113717 0.23073058]\n",
      " [0.31878301 0.93583844 0.89189002]\n",
      " [0.42469463 0.00889065 0.83619916]\n",
      " [0.48640871 0.98270821 0.25586293]\n",
      " [0.61741475 0.44802296 0.92612791]\n",
      " [0.94713173 0.02236342 0.77849365]\n",
      " [0.11672432 0.17579245 0.50416544]\n",
      " [0.57331367 0.44463314 0.98343801]\n",
      " [0.17319065 0.60175415 0.30870708]\n",
      " [0.71730414 0.72169211 0.4653075 ]\n",
      " [0.70591083 0.25333918 0.26068117]\n",
      " [0.46125714 0.1332618  0.36467304]\n",
      " [0.82481158 0.59217128 0.20926089]\n",
      " [0.54593158 0.09745452 0.74288778]\n",
      " [0.29962075 0.59722616 0.15472488]\n",
      " [0.52892375 0.61910117 0.22588448]\n",
      " [0.46579911 0.3664035  0.59925898]\n",
      " [0.22044563 0.90590866 0.84606142]\n",
      " [0.29255397 0.88657504 0.54978125]\n",
      " [0.80561369 0.9593339  0.04104502]\n",
      " [0.00876149 0.87364798 0.28852457]\n",
      " [0.00361869 0.02373978 0.7407956 ]\n",
      " [0.13613743 0.23226465 0.79341191]\n",
      " [0.32816559 0.94077607 0.9045571 ]\n",
      " [0.98382505 0.7430742  0.70285411]\n",
      " [0.19882603 0.07422635 0.73018764]\n",
      " [0.51632241 0.51525873 0.74785281]\n",
      " [0.78485615 0.32212918 0.78023386]\n",
      " [0.58106549 0.68814401 0.91666025]\n",
      " [0.23735282 0.60355419 0.38290037]\n",
      " [0.13885081 0.35552734 0.09268488]\n",
      " [0.64788235 0.16224387 0.66858677]\n",
      " [0.65915746 0.58717828 0.70023072]\n",
      " [0.93314281 0.28584385 0.61807901]\n",
      " [0.30086224 0.7575625  0.30191372]]\n",
      "Mój algorytm: [0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 0. 0. 1. 2. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.]\n",
      "Sklearn: [2 0 1 0 1 0 2 1 0 2 1 1 2 0 0 1 1 0 1 0 0 2 2 0 0 0 1 1 2 0 1 2 1 2 0 0 1\n",
      " 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Definiujemy klastrowanie i dopasowujemy je do danych\n",
    "model = HierarchicalClustering(n_clusters=3)\n",
    "model.fit(X)\n",
    "\n",
    "# Predykcje do każdego klastera\n",
    "predictions = model.labels\n",
    "\n",
    "print(X)\n",
    "print(\"Mój algorytm:\", predictions)\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
    "KF = cluster.fit_predict(X)\n",
    "print(\"Sklearn:\",KF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9242a5",
   "metadata": {},
   "source": [
    "### Porównanie\n",
    "### Aby porównać używamy silhoutte_score, które daje nam współczynnik wynik od -1 do 1, który oznacza jak dobrze są oddzielone klastry. \n",
    "### Liczba blisko -1 oznacza, że dane w klastrze są w złym miejscu i właściwie mogłyby być w kompletnie innym klastrze.\n",
    "### Liczba blisko 1 oznacza, że dane w klastrze są w dobrym miejscu i wszystkie dane są w dobrej grupie.\n",
    "### Liczba blisko 0 oznacza, że niektóre dane są dobrze oddzielone, tylko że klastry są tak podobne, że pare danych mogłyby być klastrze obok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "348e9e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 0. 0. 1. 2. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.]\n",
      "[2 0 1 0 1 0 2 1 0 2 1 1 2 0 0 1 1 0 1 0 0 2 2 0 0 0 1 1 2 0 1 2 1 2 0 0 1\n",
      " 2 1 0]\n",
      "Silhouette score algorytmu z Sickit-learn: 0.28616324002298515\n",
      "Silhouette score mojego algorytmu: 0.22897444745408216\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn import metrics\n",
    "\n",
    "HierarchicalClustering_label = predictions\n",
    "print(HierarchicalClustering_label)\n",
    "\n",
    "KF_label = KF\n",
    "print(KF_label)\n",
    "\n",
    "agg_silhouette_score1 = silhouette_score(X, KF_label)\n",
    "agg_silhouette_score2 = silhouette_score(X, HierarchicalClustering_label)\n",
    "print(\"Silhouette score algorytmu z Sickit-learn:\",agg_silhouette_score1)\n",
    "print(\"Silhouette score mojego algorytmu:\",agg_silhouette_score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a9d4f1",
   "metadata": {},
   "source": [
    "### Wniosek\n",
    "### Silhouette score algorytmu z Sickit-learn: 0.28616324002298515\n",
    "### Silhouette score mojego algorytmu: 0.22897444745408216\n",
    "\n",
    "### Silhoutte score wyszedł blisko zera w takim razie oznacza oba algorytmy z Sickit-learna i mojego algorytmu nie działają najgorzej, ale przez to że dane są do siebie dość podobno to klastry mogą na siebie nachodzić"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
